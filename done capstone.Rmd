---
title: "Capstone Data"
output: html_document
---

```{r}
library(NLP)
library(tm)
library(SnowballC)
library(stringr)
library(ngram)
library(tidytext)
```

```{r}
## Set working directory
#setting my data
## Datafile from coursera website
file <- "https://d396qusza40orc.cloudfront.net/dsscapstone/dataset/Coursera-SwiftKey.zip"
file <- options(stringsAsFactors = FALSE)

#Loading the data
blogs <- readLines("C:/Users/Kyra Hull/Downloads/Coursera-SwiftKey/final/en_US/en_US.blogs.txt", warn=FALSE, encoding = "UTF-8", skipNul = TRUE)

news <- readLines("C:/Users/Kyra Hull/Downloads/Coursera-SwiftKey/final/en_US/en_US.news.txt", warn=FALSE, encoding="UTF-8", skipNul=TRUE)
twitter <- readLines ("C:/Users/Kyra Hull/Downloads/Coursera-SwiftKey/final/en_US/en_US.twitter.txt", encoding = "UTF-8", skipNul = TRUE)

```

```{r}
#Sampling the data
set.seed(150)
sampleTwitter <- twitter[sample(1:length(twitter),500)]
sampleBlogs <- blogs[sample(1:length(blogs),500)]
sampleNews <- news[sample(1:length(news),500)]
eng.sample <- c(sampleNews, sampleBlogs, sampleTwitter)
#remove(twitter, blogs, news, sampleTwitter, sampleBlogs,sampleNews)
#String <- stri_enc_toascii(eng.sample)
#String <- stri_replace_all_regex(String , '\032', '')
#eng.data <- Corpus(VectorSource(String))
#save(eng.data, file = 'eng.data.rdata')
#remove(String, eng.sample)
#W_Line(eng.data, "en_US/eng.data.txt" )
```
eng.sample


#merge the data
```{r}
corpus <- function(eng.sample) {
# swap all sentence ends with code 'ootoo'
corpus <- gsub(pattern=';|\\.|!|\\?', x=corpus, replacement='ootoo')

# force all characters to lower case
corpus <- tolower(corpus)

# remove contiguous spaces
corpus <- gsub(pattern="\\s+", x=corpus, replacement=' ')

# split sentences by split code
corpus <- unlist(strsplit(x=corpus, split='ootoo',fixed = TRUE))
        return (corpus)
}

corpus_sentences<-c(corpus)
saveRDS(corpus_sentences, file = "Corpus_Sentence.rdata")
```
corpus
```{r}
test_sentence <- "this is a big sentence"

library(ngram)
ng_2 <- ngram(test_sentence , n=2)
print(ng_2 )

```


```{r}
Trim <- function( x ) {
        # http://stackoverflow.com/questions/2261079/how-to-trim-leading-and-trailing-whitespace-in-r
        gsub("(^[[:space:]]+|[[:space:]]+$)", "", x)
}

```

```{r}
Get_Ngrams <- function(sentence_splits, ngram_size=2) {
        ngrams <- c()
        for (sentence in sentence_splits) {
                sentence <- Trim(sentence)
                if ((nchar(sentence) > 0) && (sapply(gregexpr("\\W+", sentence), length) >= ngram_size)) {
                        ngs <- ngram(sentence , n=ngram_size)
                        ngrams <- c(ngrams, get.ngrams(ngs))
                }
        }
        return (ngrams)
}



n2 <- Get_Ngrams(corpus_sentences, ngram_size=2)
n3 <- Get_Ngrams(corpus_sentences, ngram_size=3)
n4 <- Get_Ngrams(corpus_sentences, ngram_size=4)

# consolidate all n-gram vectors into one
n_all <- c(n2, n3, n4)
write.csv(n_all,n_all_ngram.csv', row.names=FALSE)
```

```{r}
head(n_all)

```

```{r}
length(n_all)

```

```{r}
# notice the trailing space at end to avoid picking last word
word <- 'infection '

matches <- c()
for (sentence in n_all) {
        # find exact match with double backslash and escape
        if (grepl(paste0('\\<',word), sentence)) {
                print(sentence)
                matches <- c(matches, sentence)
        }
}

# find highest probability word
precision_match <- c()
for (a_match in matches) {
        # how many spaces in from of search word
        precision_match <- c(precision_match,nchar(strsplit(x = a_match, split = word)[[1]][[1]]))
}

matches



# use highest number and a random of highest for multiples
best_matched_sentence <- sample(matches[precision_match == max(precision_match)],size = 1)

print(best_matched_sentence)
```

```{r}
# split the best matching sentence by the search word
best_match <- strsplit(x = best_matched_sentence, split = word)[[1]]
# split second part by spaces and pick first word
best_match <-  strsplit(x = best_match[[2]], split = " ")[[1]]
best_match <- best_match[[1]]

print(best_match)
```

